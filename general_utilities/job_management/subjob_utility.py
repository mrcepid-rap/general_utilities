import os
import dxpy
import inspect

from time import sleep
from enum import Enum, auto
from importlib import import_module
from typing import TypedDict, Dict, Any, List, Optional

from general_utilities.import_utils.file_handlers.dnanexus_utilities import download_dxfile_by_name
from general_utilities.job_management.command_executor import build_default_command_executor, CommandExecutor
from general_utilities.job_management.joblauncher_interface import JobLauncherInterface, JobInfo
from general_utilities.platform_utils.platform_factory import PlatformFactory, Platform


class DXJobDict(TypedDict):
    """A TypedDict that stores information about a job.

    :cvar job_class: An object of :func:`dxpy.DXJob()` that contains information necessary for DNANexus to find this
        job
    :cvar job_info: A :func:`JobInfo()` TypedDict that contains job information necessary to monitor jobs generated by
        the :func:`JobStatus()` class
    """
    job_class: dxpy.DXJob
    job_info: JobInfo


class RunningStatus(Enum):
    """A more succinct version of JobStatus than that defined by DNANexus.
    """

    # DO NOT remove the '()' after auto, even though pycharm says it is wrong. IT IS NOT WRONG.
    COMPLETE = auto()
    RUNNING = auto()
    FAILED = auto()


class JobStatus(Enum):
    """The purpose of this Enum is to allow easy translation of DNANexus-specific job-status into a format with
    easily-defined logic. This logic is actually defined in the RunningStatus enum.

    For more information on these types, see
    https://documentation.dnanexus.com/user/running-apps-and-workflows/job-lifecycle
    """
    DONE = RunningStatus.COMPLETE
    IDLE = RunningStatus.RUNNING
    RUNNABLE = RunningStatus.RUNNING
    RUNNING = RunningStatus.RUNNING
    WAITING_ON_OUTPUT = RunningStatus.RUNNING
    WAITING_ON_INPUT = RunningStatus.RUNNING
    TERMINATING = RunningStatus.RUNNING
    TERMINATED = RunningStatus.FAILED
    FAILED = RunningStatus.FAILED


class Priority(Enum):
    """DNANexus-style priority levels for jobs as an Enum to enforce possible values."""

    LOW = 'low'
    NORMAL = 'normal'
    HIGH = 'high'


class SubjobUtility(JobLauncherInterface):
    """A class that contains information on, launches, and monitors subjobs on the DNANexus platform.

    This class implements the JobLauncherInterface, meaning it provides consistent behavior
    across multiple backends (e.g., SubjobUtility, ThreadUtility). In particular, it defines:

    - Iteration protocol methods (__iter__, __next__, __len__) so that completed job outputs
      can be consumed directly in for-loops or converted to lists.
    - The _print_status() method for periodic job status reporting.

    This class functions in two ways, depending on the methods used to queue jobs:

    1. If you are looking to launch an applet from a local machine, you can call this class manually and run from
    a local machine (e.g., a macbook) via :func:launch_applet() – This will launch new jobs that are
    not dependent on any current running job.

    2. For all other uses, you should use the joblauncher_factory() method to instantiate the Subjob class (if on DNA Nexus)
    or the ThreadUtility class (if on a local machine). This factory method will automatically detect the platform
    and instantiate the correct class. Both classes implement the same interface, so they can be used
    interchangeably. Run the desired function via :func:launch_job() & :func:submit_and_monitor().

    See individual method documentation for more information, but briefly, the workflow for using this class is
    the following:

    1. Queue jobs using either the :func:launch_applet() or :func:launch_job(). Do NOT use both with the same
    constructor (there are checks to prevent this)!

    2. Submit jobs that have been queued with :func:submit_queue(). After calling this method, the queue closes
    and new jobs can no longer be added to prevent iteration errors when collecting job output.

    3. Collect jobs using the built-in iterator (specified by the :func:__iter__() dunder method).

    A brief example follows::

        # Call this class with the default constructor
        subjob_utility = SubjobUtility()

        # Add jobs to the queue
        phenotype = 'cardiac_arrest'
        for chromosome in range(1,23):
            subjob_utility.launch_job(function=burden_interaction,
                                      inputs={'chromosome': chromosome,
                                              'pheno_name': phenotype},
                                      outputs=['outfile', 'outname'],
                                      instance_type='mem3_ssd1_v2_x8',
                                      name=f'{chromosome}_{phenotype}_subjob')

        # Launch jobs on DNANexus
        subjob_utility.submit_queue()

        # Collect outputs:
        outputs = []
        # 1st for-loop iterates over individual jobs
        for output in subjob_utility:
            # Each output is either the actual value, or if a file, a dxpy.DXLink() reference to a file OR a
            # pathlib.Path to that file on the local file system if self._download_oncomplete is True

            # 2nd for-loop iterates over outputs
            for output_key, output_value in output.items():
                print(f'Output for {output_key}: {output_value}')
                outputs.append(output_value)

            # Or, the user can also directly query the output using the name given to the launch_job method
            # outputs param:
            print(f'output for the outname value is: {output["outname"]})

    :param incrementor: This class will print a status method for every :param:incrementor jobs completed with a
        percentage of total jobs completed. [500]
    :param concurrent_job_limit: Number of jobs that can be run at once. Default of 100 is the actual limit for
        concurrent jobs on the DNANexus platform. It is also wishful in that you will rarely be able to have 100
        jobs simultaneously running. [100]
    :param instance_type: The default instance type to use for jobs. If None (default), the instance type
        defined in the parent job will be used.
    :param download_on_complete: Should ALL file outputs be downloaded on subjob completion? Setting this
        option to 'True' will download all files to the current instance and provide a :func:Path. If 'False'
        (default), the value in the output dictionary will be a :func:dxpy.dxlink(). [False]
    :param priority: The priority of the job. This is a string that can be 'low', 'normal', or 'high'. [low]
    """

    def __init__(self,
                 incrementor: int = 500,
                 concurrent_job_limit: int = 100,
                 instance_type=None,
                 download_on_complete: bool = False,
                 priority: Priority = Priority.LOW) -> None:

        super().__init__(incrementor=incrementor,
                         concurrent_job_limit=concurrent_job_limit)

        # Dereference class parameters
        self._instance_type = instance_type
        self._download_on_complete = download_on_complete
        self._priority = priority

        # We define two different queues for use during runtime:
        # job_running – jobs currently running, with a dict keyed on the DX job-id and with a value of DXJobDict class
        #   which contains the job class from instantiation and information about the job
        #   and information about the job
        # job_failed  – A list of jobs which failed during runtime which, if the job has additional retries, can
        #   be resubmitted
        self._job_running: Dict[str, DXJobDict] = dict()
        self._job_failed: List[JobInfo] = []

        # Job type & count monitoring
        self._queue_type = PlatformFactory().get_platform()

        # Set default job instance type
        self._set_default_instance_type()

    def launch_applet(self, applet_hash: str, inputs: Dict[str, Any], outputs: List[str] = None,
                      destination: str = None, instance_type: str = None, name: str = None) -> None:
        """Launch a DNANexus job with the given parameters from a LOCAL machine.

        The only required parameters for this function are :param:applet_hash and :param:inputs. This method will add
        a job with input parameters provided by this method call to the class :param:self._job_queue.

        DO NOT use this method if operating within a current DNANexus job. There may be unforeseen consequences...

        :param applet_hash: The applet hash for the applet that should be run (e.g., applet-1234567890ABCDEFGabcdefg)
        :param inputs: The function inputs. These must include all default inputs and be identical to those defined
            in the dxapp.json inputs section.
        :param outputs: The function outputs. These must include all default outputs and be identical to those defined
            in the dxapp.json outputs section. May be 'None' if there are no defined outputs from the given
            applet. [None]
        :param destination: Where should outputs be placed on the DNANexus platform. Default places outputs in the root
            level directory for the executing project (e.g., '/'). [None]
        :param instance_type: What instance type should be used? Default sets the instance type based on the
            'instance_type' specification in the dxapp.json. [None]
        :param name: Name of the job. Default names the job after the executing applet name. [None]
        """

        # Check if the queue has been closed by submit_queue()
        if self._queue_closed is True:
            raise dxpy.AppError('Cannot submit new subjobs after calling monitor_subjobs()!')

        # Make sure only identical job types have been launched
        if self._queue_type is Platform.DX:
            raise dxpy.AppError('Cannot mix jobtypes between launch_applet() and launch_job()!')

        self._total_jobs += 1

        # Lists are immutable, so if None is provided, set to empty
        if outputs is None:
            outputs: List[str] = []

        input_parameters: JobInfo = {'function': applet_hash,
                                       'properties': {},
                                       'input': inputs,
                                       'outputs': outputs,
                                       'job_type': Platform.LOCAL,
                                       'destination': f'/{destination}',
                                       'name': f'subjob_{self._total_jobs}' if name is None else None,
                                       'instance_type': instance_type if instance_type else self._default_instance_type}

        self._job_queue.append(input_parameters)

    def launch_job(self, function, inputs: Optional[Dict[str, Any]] = None,
                   outputs: Optional[List] = None, name: Optional[str] = None,
                   instance_type: Optional[str] = None) -> None:
        """Launch a DNANexus job with the given parameters from a REMOTE machine.

        The only required parameters for this function are :param:function and :param:inputs. This method will add
        a job with input parameters provided by this method call to the class :param:self._job_queue.

        There is an entire logic for why we pass the function to the method rather than the string representation of
        the method's name:

        1. To be able to 'see' the methods of other files / packages decorated with dxpy.entry_point(), the class has
        to be imported into the calling file (e.g. 'import from'). Using the string representation makes the python
        interpreter / pycharm think that the import isn't used, so we use the actual function.

        2. We then convert to the string representation below because the DNANexus DXJob call requires a string
        representation.

        3. This also allows us to use the 'inspect' package to set a DNANexus 'property' for this job that is equal
        to the name of the containing python package. This is so that we can find this corresponding package to
        import when the subjob is launched. For more information about this, see the :func:check_subjob_decorator()
        method.

        DO NOT use this method if operating from a local machine. There may be unforeseen consequences...

        :param function: A python function (Callable type). This function MUST be decorated with the dxpy.entry_point()
            decorator, with the only parameter to this decorator being the name of the function. This name must be
            identical to the def for that function (e.g., dxpy.entry_point('test'); def test():)
        :param inputs: The function inputs. These must include all default inputs and be identical to those defined
            in call for :param:function. Only json serializable types can be included (python primitives, dict, and
            list).
        :param outputs: The function outputs. These must include all default outputs and be identical to those returned
            by the function's output. This output MUST be in the form of a named dictionary
            (e.g., outputs = {'output': 5}. May be 'None' if there are no defined outputs from the given applet. [None]
        :param instance_type: What instance type should be used? Default sets the instance type based on the
            'instance_type' specification in the dxapp.json. [None]
        :param name: Name of the job. Default names the job after the executing applet and :param:function name. [None]
        """

        # Check if the queue has been closed by submit_queue()
        if self._queue_closed is True:
            raise dxpy.AppError('Cannot submit new subjobs after calling monitor_subjobs()!')

        # Make sure only identical job types have been launched
        if self._queue_type is Platform.LOCAL:
            raise dxpy.AppError('Cannot mix jobtypes between launch_applet() and launch_job()!')

        self._total_jobs += 1

        # Lists are immutable, so if None is provided, set to empty
        if outputs is None:
            outputs: List[str] = []

        input_parameters: JobInfo = {'function': function,
                                       'properties': {'module': inspect.getmodule(function).__name__},
                                       'input': inputs,
                                       'outputs': outputs,
                                       'job_type': Platform.DX,
                                       'destination': None,
                                       'name': None if name is None else name,
                                       'instance_type': instance_type if instance_type else self._default_instance_type}

        self._job_queue.append(input_parameters)

    def submit_and_monitor(self) -> None:
        """Submit the job queue created by adding jobs to launch_applet / launch_job and wait for submitted jobs to
        finish executing.

        This method submits all jobs added to self._job_queue to the DNANexus job scheduler. It also manages watching
        jobs and checking when they complete or fail. To note: when subjob spot instances generated from a currently
        running DNANexus job fail due to a SpotInstanceInterruption, they bypass this checking process and will
        always fail the parent process

        Importantly, when all jobs finish, this method waits until the next iteration period as defined by
        """

        # Close the queue to future job submissions to save my sanity for weird edge cases
        self._queue_closed = True

        self._logger.info(f'{"Total number of jobs to iterate through":{65}}: {self._total_jobs}')

        # submit and monitor jobs
        self._monitor_subjobs()

        if len(self._job_failed) > 0:
            self._logger.info('All jobs completed, printing failed jobs...')
            for failed_job in self._job_failed:
                self._logger.error(f'FAILED: {failed_job}')
        else:
            self._logger.info('All jobs completed, No failed jobs...')

    def _monitor_subjobs(self) -> None:
        """This method is the primary monitoring point for queued, submitted, and finished jobs.

        This method will first check to see if there are any jobs in the job queue, and if the number of currently
        running jobs is less than self._concurrent_job_limit, will attempt to submit new jobs according to the type of
        job (:func:Platform).

        If there are no more jobs to submit, it will then automatically monitor submitted jobs for a completed
        :func:JobStatus.
        """

        # Set a boolean for allowing to submit jobs UNTIL we hit the job limit (defined by self._concurrent_job_limit)
        can_submit = True

        # Only run the submission process while jobs are still in the queue
        while len(self._job_queue) > 0:

            job = self._job_queue.pop()

            # Make sure the queue isn't full...
            # If it is, go to sleep for 60s and check again
            while can_submit is False:
                if len(self._job_running.keys()) < self._concurrent_job_limit:
                    can_submit = True

                self._print_status()
                self._monitor_submitted()
                sleep(60)

            if job['job_type'] == Platform.DX:
                dxjob = dxpy.new_dxjob(fn_input=job['input'], fn_name=job['function'].__name__, instance_type=job['instance_type'],
                               properties=job['properties'], name=job['name'])

            elif job['job_type'] == Platform.LOCAL:
                dxapplet = dxpy.DXApplet(job['function'])
                dxjob = dxapplet.run(applet_input=job['input'], folder=job['destination'], name=job['name'],
                                     instance_type=job['instance_type'], priority=self._priority.value)

            else:
                raise RuntimeError('Job does not have type DX or LOCAL, which should be impossible')

            # Build a dict that contains all information necessary to monitor AND resubmit this job (if necessary)
            self._job_running[dxjob.describe(fields={'id': True})['id']] = {'job_class': dxjob,
                                                                            'job_info': job}

            # Lock the submission process until we have space to launch additional jobs
            if len(self._job_running.keys()) >= self._concurrent_job_limit:
                can_submit = False

        self._monitor_submitted()

    def _check_job_status(self, job: DXJobDict) -> RunningStatus:
        """A helper function that checks if a job is finished and collects outputs from finished jobs.

        This method first generates a JobStatus Enum by checking the current DNANexus job status using the DXJob
        object stored in the DXJobDict object by calling :func:dxpy.DXJob.describe(). This JobStatus is then
        translated into a RunningStatus Enum which codes for only Complete / Running / Failed jobs to simplify the
        decision process of deciding the end-point of a given job. Finally, a job is RunningStatus.COMPLETE,
        we use the DXJobDict-defined outputs to retrieve :func:dxpy.dxlink() for those outputs and add them to
        self._output_array.

        if self._download_on_complete is True, we also download all files directly to

        To be clear, this method could be contained within :func:self._monitor_submitted(), but was easier to follow
        when abstracted into a separate method.

        :param job: A DXJobDict TypedDict object containing information about a job.
        :return: A :func:RunningStatus enum indicating the status of the current job.
        """

        description = job['job_class'].describe(fields={'state': True})
        curr_status = JobStatus[description['state'].rstrip().upper()]
        if curr_status.value == RunningStatus.COMPLETE:
            output_dict = {}
            if len(job['job_info']['outputs']) > 0:
                # Do a describe() call here, so we only have to do it once to save time
                output_values = job['job_class'].describe()['output']
                for output in job['job_info']['outputs']:

                    output_ref = job['job_class'].get_output_ref(output)
                    output_key = output_ref['$dnanexus_link']['field']
                    output_value = output_values[output_key]

                    # Need to check if they are files...
                    # This is if the output is a list
                    if type(output_value) is list:
                        new_values = []
                        for value in output_value:
                            # This is possibly (likely) a file
                            if '$dnanexus_link' in value:
                                if value['$dnanexus_link'].startswith('file-'):
                                    if self._download_on_complete:  # Download the file if the user wants it locally
                                        new_values.append(download_dxfile_by_name(value, print_status=False))
                                    else:
                                        new_values.append(value)
                                else:
                                    new_values.append(value)

                            # This is unlikely to be a file
                            else:
                                new_values.append(value)

                        output_dict[output_key] = new_values

                    # This is if the output is just a single value
                    else:
                        # Dictionaries are possibly (likely) a file.
                        # In fact – I don't think dictionaries can happen here unless they are files, but adding
                        # else statements just to make sure.
                        if type(output_value) is dict:
                            if '$dnanexus_link' in output_value:
                                # This is still likely a file...
                                if output_value['$dnanexus_link'].startswith('file-'):
                                    if self._download_on_complete:  # Download the file if the user wants it locally
                                        output_dict[output_key] = download_dxfile_by_name(output_value,
                                                                                          print_status=False)
                                    else:
                                        output_dict[output_key] = output_value
                                else:  # This is something else that I don't think actually exists in DNANexus...
                                    output_dict[output_key] = output_value
                            else:  # I don't think this else can happen, but adding it just to be sure
                                output_dict[output_key] = output_value
                        # This is unlikely to be a file
                        else:
                            output_dict[output_key] = output_value

            self._output_array.append(output_dict)
            self._num_completed_jobs += 1
            self._print_status()

        return curr_status.value

    def _monitor_submitted(self) -> None:
        """Iterate through all currently running jobs and decide if they are finished, complete, or failed.

        This method wraps :func:self._check_job_status(). It takes the output of that function and decides whether
        to, if:

        * Completed: remove the (completed) job from the job_running dict

        * Failed: Remove the failed job from the job_running_dict

        * Running: Continue to monitor the job until completed
        """

        curr_keys = list(self._job_running.keys())
        for job_id in curr_keys:
            job_status = self._check_job_status(self._job_running[job_id])
            if job_status is RunningStatus.COMPLETE:
                del self._job_running[job_id]
            elif job_status is RunningStatus.FAILED:
                job = self._job_running[job_id]['job_info']
                del self._job_running[job_id]
                self._job_failed.append(job)

    def _set_default_instance_type(self) -> None:
        """Set the default instance type from the parent DNANexus job if available."""
        if 'DX_JOB_ID' in os.environ:
            parent_job = dxpy.DXJob(dxid=os.getenv('DX_JOB_ID'))
            self._default_instance_type = \
                parent_job.describe(fields={'systemRequirements': True})['systemRequirements']['*']['instanceType']
        else:
            self._default_instance_type = None


def check_subjob_decorator() -> Optional[str]:
    """This class checks to see if the dx Applet is actually a subjob being run on the DNANexus platform.

    To be able to run subjobs on DNANexus, the class / method MUST be imported using standard python imports (e.g.,
    import ... from ...) by the instantiating file that contains the dxpy.entry_point('main') decorator. This means
    that modules (e.g., 'burden') that are dynamically loaded WILL NOT be found in the python classpath prior to
    DNANexus attempting to launch the subjob with the indicated dxpy.entry_point() decorator. To solve this, we do two
    things:

    1. For all subjobs being launched, we add a property to the job indicating where this method
    (check_subjob_decorator) should look for the decorated method (see JobInfo in this file for more information).

    2. When the new subjob is launched, we then run this method before dxpy.run() is called to make sure that the
    decorated method is properly included in the dxpy.utils.exec_utils.ENTRY_POINT_TABLE dict that tells the DNANexus
    job handler what function to run at startup. This approach uses the import_module function from importlib to
    dynamically load the requested methods into the python classpath

    :return: The name of the identified module that was loaded by this method or None if no module was loaded
    """

    loaded_module = None
    job = dxpy.DXJob(dxpy.JOB_ID)
    if 'module' in job.describe()['properties']:
        loaded_module = job.describe()['properties']['module']
        try:
            import_module(loaded_module)
        except ModuleNotFoundError:
            raise

    return loaded_module


def prep_current_image(required_files: List[dict]) -> CommandExecutor:
    """A helper function for launched subjobs that automatically downloads the required Docker image and downloads
    any requisite files

    :param required_files: A list of :func:`dxpy.dxlink()` dictionaries of files to download
    :return: The CommandExecutor for running jobs on the instance
    """

    cmd_executor = build_default_command_executor()

    for file in required_files:
        download_dxfile_by_name(file, print_status=False)

    return cmd_executor