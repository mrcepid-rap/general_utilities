import csv
import re
from pathlib import Path
from typing import Set, List, Tuple

from general_utilities.import_utils.file_handlers.input_file_handler import InputFileHandler
from general_utilities.job_management.command_executor import CommandExecutor
from general_utilities.mrc_logger import MRCLogger


class GeneticsLoader:
    """Process genetic data from genotyping chips provided by UKBiobank

    This class filters the 'raw' genetic array data generated by mrcepid-buildgrms down to the set of individuals with
    both complete phenotype and covariate information and removing individuals as requested by the user. If using
    datatypes OTHER than WES (which is handled in mrcepid-buildgrms) this class also synchronises samples between these
    datatypes to avoid issues with various association tools.

    :param bed_file: Plink .bed format file
    :param fam_file: Plink .fam format file
    :param bim_file: Plink .bim format file
    :param sample_files: A List of .bgen format sample files to synchronise samples on.
    :param cmd_executor: CommandExecutor class to run system calls through
    :param low_mac_list: An optional list of low minor allele count variants for exclusion when running BOLT
    """

    def __init__(self, bed_file: InputFileHandler, fam_file: InputFileHandler, bim_file: InputFileHandler,
                 sample_files: List[Path],
                 cmd_executor: CommandExecutor, low_mac_list: InputFileHandler = None,
                 sparse_grm: InputFileHandler = None, sparse_grm_sample: InputFileHandler = None):

        self._logger = MRCLogger(__name__).get_logger()
        self._cmd_executor = cmd_executor

        self._bed_file = bed_file
        self._fam_file = fam_file
        self._bim_file = bim_file
        self._low_mac_list = low_mac_list
        self._sparse_grm = sparse_grm
        self._sparse_grm_sample = sparse_grm_sample

        bed_filename, bim_filename, fam_filename = self._ingest_genetic_data()

        if self._sparse_grm is not None:
            self._sparse_grm, self._sparse_grm_sample = self._ingest_sparse_matrix()

        if len(sample_files) > 0:  # Only do this is sample file(s) are provided to synchronise on
            self._logger.info('Multiple sample data types detected, synchronising sample lists...')
            self._union_sample = self._write_union_sample(sample_files)
            self._synchronise_genetic_data()
        self._filtered_bed, self._filtered_bim, self._filtered_fam = self._generate_filtered_genetic_data(bed_filename,
                                                                                                          bim_filename,
                                                                                                          fam_filename)

    def get_filtered_genetic_filename(self) -> str:
        """Getter method to retrieve filtered genetic filenames.

        This method simply returns the filename of the filtered genetic data.

        :return: string representing the name of the filtered genetic data file.
        """
        return self._filtered_bed.name

    def get_sparsematrix(self) -> Path:
        """Getter method to retrieve sparse matrix filenames.

        This method returns the paths of the sparse genetic matrix and its corresponding sample file.

        :return: A Tuple containing the paths to the sparse genetic matrix and its sample file.
        """
        return self._sparse_grm

    def get_sparsematrix_sample(self) -> Path:
        """Getter method to retrieve sparse matrix paths.

        This method returns the paths of the sparse genetic matrix and its corresponding sample file.

        :return: A tuple containing the paths to the sparse genetic matrix and its sample file.
        """
        return self._sparse_grm_sample

    def get_low_mac_list(self) -> Path:
        """Getter method to retrieve low MAC list filename.

        This method returns the filename of the low MAC list.

        :return: Path to the low MAC list file.
        """
        return self._low_mac_list.get_file_handle()

    def _ingest_genetic_data(self) -> Tuple[Path, Path, Path]:
        """Downloads provided genetic data in plink binary format to this instance.

        These files provided to this method should point to the processed genetic data curated by the mrcepid-makegrm
        applet of this workflow. An optional low_mac_list for BOLT can also be provided

        :return: a Tuple of the plink binary files (bed, bim, fam) that were downloaded
        """

        # download the genotype data
        bed_filename = self._bed_file.get_file_handle()
        bim_filename = self._bim_file.get_file_handle()
        fam_filename = self._fam_file.get_file_handle()

        if self._low_mac_list is not None:
            # Download the low MAC list
            self._low_mac_list.get_file_handle()

        self._logger.info('Genetic array data downloaded...')

        return bed_filename, bim_filename, fam_filename

    @staticmethod
    def _generate_sample_set(sample_path: Path) -> Set[str]:
        """Read a sample file and add all samples within it to a set()

        :param sample_path: Path to a sample file
        :return: A set containing string representations of all samples in the file passed to sample_path
        """

        sample_set = set()
        with sample_path.open('r') as sample_file:
            for sample in sample_file:
                sample = sample.rstrip().split()
                if sample[0] != "ID_1" and sample[0] != "0":
                    sample_set.add(sample[1])

        return sample_set

    def _write_union_sample(self, sample_paths: List[Path]) -> Path:
        """Merge some number of sample files into a single intersected sample file

        This method uses the :func:`_generate_sample_set` to load 'N' sample files into independent sets,
        finds the intersection of these sets and then writes that intersection to a new sample file. This file is
        returned as a Path representation. Files processed by this method must be in standard plink / bgen format.
        The union sample file written by this method is NOT safe for any external tool(s) and is meant to just pass
        through the GeneticsLoader() class if required.

        :param sample_paths: a List of Paths to sample files
        :return: A Path representation of the union sample file
        """

        union_samples = set()
        for sample_path in sample_paths:
            if len(union_samples) > 0:
                union_samples = union_samples.intersection(self._generate_sample_set(sample_path))
            else:
                union_samples = self._generate_sample_set(sample_path)

        union_sample_path = Path('union.sample')
        with union_sample_path.open('w') as union_file:
            union_file.write('ID_1 ID_2\n')
            union_file.write('0 0\n')
            for sample in union_samples:
                union_file.write(f'{sample} {sample}\n')

        return union_sample_path

    def _synchronise_genetic_data(self) -> None:
        """Synchronise imputed and genetic data to ensure correct individuals are in each file

        Sometimes the imputed/dosage/WES data may have fewer individuals than the genetics bed files. This method
        rectifies that.

        Specifically, this method synchronises the samples of three files:
        1. SAMPLES_Include.txt (Genetics individuals processed down to those with phenotype / covariate information)
        2. dosage/imputed samples
        3. phenotypes_covariates.formatted.txt â€“ not necessary to ask for these samples at first as they are
              identical to SAMPLES_Include.txt

        We also generate a remove_SAMPLES.txt for BOLT to make it faster for processing this data when we are running
        association tests.

        :return: None
        """

        # 1. Read in imputed / dosage samples and get an intersection with SAMPLES_Include.txt
        include_path = Path('SAMPLES_Include.txt')
        with self._union_sample.open('r') as sample_file, \
                include_path.open('r') as include_file:

            testing_samples = set()
            for sample in sample_file:
                sample = sample.rstrip().split()
                if sample[0] != "ID_1" and sample[0] != "0":
                    testing_samples.add(sample[1])
            self._logger.info(f'{"Number of dosage / imputed samples":<65}: {len(testing_samples)}')

            # Genetic/covariate should be identical since we process them earlier, but just making sure here...
            genetic_samples = set()
            for sample in include_file:
                sample = sample.rstrip().split()[0]
                genetic_samples.add(sample)

            self._logger.info(f'{"Number of .bed samples":<65}: {len(genetic_samples)}')
            valid_samples = testing_samples.intersection(genetic_samples)
            self._logger.info(f'{"Number of union samples":<65}: {len(valid_samples)}')

        # 2. Read in the processed phenotypes/covariates file and print out a new file based on the intersection with
        # 'valid_samples'.
        combo_path = Path('phenotypes_covariates.formatted.txt')
        new_include_path = Path('SAMPLES_Include.genetic_matched.txt')
        new_combo_path = Path('phenotypes_covariates.formatted_new.txt')

        with combo_path.open('r') as formatted_combo_file, \
                new_include_path.open('w') as new_include_file, \
                new_combo_path.open('w') as new_formatted_combo_file:

            # Here we just take this iteration opportunity to add in the 'array_batch' covariate for imputed data
            base_covar_reader = csv.DictReader(formatted_combo_file, delimiter=' ')
            indv_written = 0  # Just to count the number of samples we will analyse
            combo_writer = csv.DictWriter(new_formatted_combo_file,
                                          fieldnames=base_covar_reader.fieldnames,
                                          quoting=csv.QUOTE_NONE,
                                          delimiter=' ',
                                          lineterminator='\n')

            combo_writer.writeheader()
            for indv in base_covar_reader:
                if indv['FID'] in valid_samples:
                    combo_writer.writerow(indv)
                    new_include_file.write(f'{indv["FID"]} {indv["FID"]}\n')
                    indv_written += 1

            self._logger.info(f'{"Number of INCLUDE samples":<65}: {indv_written}')

        new_combo_path.replace(combo_path)
        new_include_path.replace(include_path)

        # 3. Finally, we need to go back through the genetic data and write out samples that we need to exclude...
        # Read in valid samples from the imputed data, crosscheck the valid covariate samples, and write the
        # result to a new file:
        # I am unsure if this is necessary for the dosage format, but going to do it again to be sure...
        remove_path = Path('SAMPLES_Remove.txt')
        new_remove_path = Path('SAMPLES_Remove.genetic_matched.txt')
        with self._union_sample.open('r') as sample_file, \
                new_remove_path.open('w') as remove_file:

            num_exclude = 0
            for sample in sample_file:
                data = sample.rstrip().split()
                if data[1] not in valid_samples and data[0] != "ID_1" and data[0] != "0":
                    remove_file.write(f'{data[1]} {data[1]}\n')
                    num_exclude += 1

            self._logger.info(f'{"Number of REMOVE samples":<65}: {num_exclude}')

        new_remove_path.replace(remove_path)

    def _generate_filtered_genetic_data(self, bed_filename, bim_filename, fam_filename) -> Tuple[Path, Path, Path]:
        """Generates a genetic file plink binary dataset filtered to only individuals we want to include in association
            tests

        This method takes the SAMPLES_Include.txt file created by ingest_data OR re-processed using methods included
        in this class and uses it as the --keep parameter in plink2 to filter the original set of ~500k individuals
        to those individuals requested by the user. This method will also then return the number of individuals in the
        final dataset to ensure filtering completed properly.

        :return: None
        """
        # Extract the stems (filenames without extensions)
        bed_stem = Path(bed_filename).stem
        bim_stem = Path(bim_filename).stem
        fam_stem = Path(fam_filename).stem

        # Check if all stems are the same
        if bed_stem == bim_stem == fam_stem:
            genetic_data = bed_stem
        else:
            raise ValueError("The stems for the files do not match!")

        # Generate a plink file to use that only has included individuals:
        cmd = f'plink2 ' \
              f'--bfile /test/{genetic_data} --make-bed --keep-fam /test/SAMPLES_Include.txt ' \
              f'--out /test/Autosomes_QCd_WBA'

        self._cmd_executor.run_cmd_on_docker(cmd, stdout_file=Path('plink_filtered.out'))

        # I have to do this to recover the sample information from plink
        with Path('plink_filtered.out').open('r') as plink_out:
            for line in plink_out:
                count_matcher = re.match('(\\d+) samples \(\\d+ females, \\d+ males; \\d+ founders\) remaining after',
                                         line)
                if count_matcher:
                    self._logger.info(f'{"Plink individuals written":{65}}: {count_matcher.group(1)}')

        filtered_bed = Path('Autosomes_QCd_WBA.bed')
        filtered_bim = Path('Autosomes_QCd_WBA.bim')
        filtered_fam = Path('Autosomes_QCd_WBA.fam')

        return filtered_bed, filtered_bim, filtered_fam

    def _ingest_sparse_matrix(self) -> Tuple[Path, Path]:
        """Download the sparse matrix for use by GLM/STAAR.

        This method allows easier use by modules that only require the sparse matrix and not the Plink genetics files,
        while keeping it in an obvious place for maintainability.

        :return: A tuple containing the sparse genetic matrix and its corresponding sample file.
        """

        # Downloads the sparse matrix
        sparse_grm = self._sparse_grm.get_file_handle()
        sparse_grm_sample = self._sparse_grm_sample.get_file_handle()

        return sparse_grm, sparse_grm_sample
